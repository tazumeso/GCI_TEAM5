{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "test_data = pd.read_csv(\"./data/test.csv\")\n",
    "id_period_mapping = pd.read_csv(\"./data/id_period_mapping.csv\")\n",
    "test_data[\"period\"] = id_period_mapping[\"period\"]\n",
    "sample_submission = pd.read_csv(\"./data/sample_submit.csv\", header=None)\n",
    "test_data.index = test_data[\"data_id\"]\n",
    "\n",
    "mask = (train_data[\"period\"] == \"train9\") | (train_data[\"period\"] == \"train6\") | (train_data[\"period\"] == \"train4\") | (train_data[\"period\"] == \"train7\") | \\\n",
    "(train_data[\"period\"] == \"train5\") | (train_data[\"period\"] == \"train3\") | (train_data[\"period\"] == \"train1\") | (train_data[\"period\"] == \"train14\") | \\\n",
    "(train_data[\"period\"] == \"train13\") | (train_data[\"period\"] == \"train11\") | (train_data[\"period\"] == \"train10\") | (train_data[\"period\"] == \"train2\") | \\\n",
    "(train_data[\"period\"] == \"train12\") | (train_data[\"period\"] == \"train10\") | (train_data[\"period\"] == \"train14\")\n",
    "train_data = train_data[mask]\n",
    "\n",
    "train_y = train_data.iloc[:, -1]\n",
    "\n",
    "l = [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14]\n",
    "dfx = pd.DataFrame()\n",
    "for i in l:\n",
    "    dfi = train_data[train_data.period == \"train{}\".format(i)].iloc[:, 2:90]\n",
    "    dfx = dfx.append((dfi - dfi.mean()) / dfi.std())\n",
    "train_X = dfx\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(1, 11):\n",
    "    dfi = test_data[test_data.period == \"test{}\".format(i)].iloc[:, 1:-1]\n",
    "    dfx = dfx.append((dfi - dfi.mean()) / dfi.std())\n",
    "test_X = dfx\n",
    "test_X = test_X.loc[test_data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_train_X = pd.concat([train_X, test_X])\n",
    "\n",
    "\n",
    "# concat_train_X = concat_train_X.drop([u'c5', u'c6', u'c7', u'c8', u'c10', u'c13', u'c17', u'c18', u'c19',\n",
    "#        u'c23', u'c28', u'c32', u'c34', u'c37', u'c41', u'c42', u'c45', u'c46',\n",
    "#        u'c52', u'c54', u'c55', u'c58', u'c60', u'c62', u'c63', u'c65', u'c70',\n",
    "#        u'c75', u'c82', u'c84', u'c85', u'c86', #欠損値\n",
    "#        u'c38', u'c49', u'c69', u'c29', u'c79', u'c83', u'c77', u'c1', u'c51', #追加 → 10にしたら悪くなる\n",
    "#        u'c72', u'c73', u'c64', u'c9', u'c78', u'c16', u'c30', u'c71', u'c83',\n",
    "#        u'c45', u'c65', u'c50', u'c87', u'c64'], axis=1)\n",
    "\n",
    "#concat_train_X = concat_train_X[[\"c12\", \"c80\", \"c48\", \"c81\"]] # 0.69218 → 0.69208\n",
    "\n",
    "concat_train_X = concat_train_X[[\"c12\", \"c80\", \"c48\", \"c81\",\n",
    "                                 \"c68\", \"c56\", \"c27\", \"c67\", \"c20\", \"c4\"]] # 0.69391\n",
    "\n",
    "concat_train_X = np.array(concat_train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単一モデルの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim=concat_train_X.shape[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(concat_train_X.shape[1]))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(concat_train_X, concat_train_X, nb_epoch=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with a Sequential model\n",
    "get_2nd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[2].output])\n",
    "layer_output = get_2nd_layer_output([concat_train_X])[0]\n",
    "\n",
    "train_feature = layer_output[:520000, :]\n",
    "test_feature = layer_output[520000:, :]\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "bias = np.ones(520000)\n",
    "train_feature = np.c_[train_feature, bias]\n",
    "bias = np.ones(361500)\n",
    "test_feature = np.c_[test_feature, bias]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アンサンブルする場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "881500/881500 [==============================] - 49s - loss: 0.4400 - acc: 0.4622    \n",
      "Epoch 2/5\n",
      "881500/881500 [==============================] - 49s - loss: 0.3871 - acc: 0.4915    - ETA: 0s - loss: 0.3870 - acc: 0.49 - ETA: 0s - lo - ETA: 0s - loss: 0.3871 - \n",
      "Epoch 3/5\n",
      "881500/881500 [==============================] - 49s - loss: 0.3709 - acc: 0.5059    - ETA: 0s - loss: - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.37\n",
      "Epoch 4/5\n",
      "881500/881500 [==============================] - 49s - loss: 0.3632 - acc: 0.5156    - ETA: 0s - loss: 0.3632 - a\n",
      "Epoch 5/5\n",
      "881500/881500 [==============================] - 49s - loss: 0.3562 - acc: 0.5224    \n",
      "Epoch 1/5\n",
      "881500/881500 [==============================] - 49s - loss: 0.4437 - acc: 0.4157    \n",
      "Epoch 2/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3900 - acc: 0.4553    - ETA: 0s - loss: 0.3900\n",
      "Epoch 3/5\n",
      "881500/881500 [==============================] - 47s - loss: 0.3741 - acc: 0.4731    \n",
      "Epoch 4/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3640 - acc: 0.4865    - ETA: 0s - loss: 0.\n",
      "Epoch 5/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3572 - acc: 0.4956    \n",
      "Epoch 1/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.4430 - acc: 0.4605    \n",
      "Epoch 2/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3894 - acc: 0.4759    - ETA: 0\n",
      "Epoch 3/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3721 - acc: 0.4881    - ETA: 1s - loss: 0.3720 - acc: 0.48 - ETA: 1s - - ETA: 0s - loss:\n",
      "Epoch 4/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3633 - acc: 0.4944    \n",
      "Epoch 5/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3590 - acc: 0.4998    - ETA: 0s - loss: 0.3590 - acc: 0.499\n",
      "Epoch 1/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.4365 - acc: 0.4214    \n",
      "Epoch 2/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3828 - acc: 0.4615    \n",
      "Epoch 3/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3636 - acc: 0.4836    \n",
      "Epoch 4/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3523 - acc: 0.5021    - ETA: 2s - loss: 0.3524  - ETA: 2s - loss: 0.3525 - acc: 0.\n",
      "Epoch 5/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3429 - acc: 0.5177    - ETA: 0s - loss: 0.3429 - acc: 0.5\n",
      "Epoch 1/5\n",
      "881500/881500 [==============================] - 49s - loss: 0.4420 - acc: 0.4820    \n",
      "Epoch 2/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3855 - acc: 0.5116    - ETA: 0s - loss: 0.3857 - acc: 0.5 - ETA: 0s - loss: 0.3857 - \n",
      "Epoch 3/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3705 - acc: 0.5198    - ETA: 0s - \n",
      "Epoch 4/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3599 - acc: 0.5238    \n",
      "Epoch 5/5\n",
      "881500/881500 [==============================] - 48s - loss: 0.3531 - acc: 0.5284    - ETA: 0s - loss: 0.3530 - acc: 0.52 - ETA: 0s - los\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "for i in range(5):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=concat_train_X.shape[1]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(concat_train_X.shape[1]))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(concat_train_X, concat_train_X, nb_epoch=5, batch_size=128)\n",
    "    \n",
    "    # with a Sequential model\n",
    "    get_2nd_layer_output = K.function([model.layers[0].input],\n",
    "                                      [model.layers[2].output])\n",
    "    layer_output = get_2nd_layer_output([concat_train_X])[0]\n",
    "\n",
    "    train_feature = layer_output[:520000, :]\n",
    "    test_feature = layer_output[520000:, :]\n",
    "\n",
    "    train_y = np.array(train_y)\n",
    "    bias = np.ones(520000)\n",
    "    train_feature = np.c_[train_feature, bias]\n",
    "    bias = np.ones(361500)\n",
    "    test_feature = np.c_[test_feature, bias]\n",
    "    \n",
    "    w = np.linalg.inv(train_feature.T.dot(train_feature)).dot(train_feature.T).dot(train_y)\n",
    "    pred = w.dot(test_feature.T)\n",
    "    pred_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[1] = np.average(pred_list, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線形回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.linalg.inv(train_feature.T.dot(train_feature)).dot(train_feature.T).dot(train_y)\n",
    "sample_submission[1] = w.dot(test_feature.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sample_submission[1][sample_submission[1] < 0.1] = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"result2.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49997308017645903"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.iloc[:, 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56558181614183145"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission[1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23333341676661412"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission[1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsf8H+S3A2x8hxL4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd729ea4048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.hist(sample_submission[1], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- アンサンブルもしたい"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
